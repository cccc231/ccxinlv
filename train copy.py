import tensorflow as tf
from tensorflow import keras
import numpy as np
import os
import datetime
from sklearn.model_selection import train_test_split # æ–°å¢ï¼šç”¨äºç§‘å­¦æ‰“ä¹±æ•°æ®

# åªæœ‰åœ¨ Windows ä¸Šæ‰ä¼šæœ‰ dll åŠ è½½é—®é¢˜
if os.name == 'nt':
    try:
        ctypes = __import__('ctypes')
        ctypes.windll.LoadLibrary('cudart64_110.dll')
        print("âœ… æ­å–œï¼šCUDA åŠ¨æ€åº“åŠ è½½æˆåŠŸï¼")
    except OSError:
        print("âŒ å¤±è´¥ï¼šæ‰¾ä¸åˆ° 'cudart64_110.dll'ã€‚")

# --- æ˜¾å¡é…ç½® ---
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

# --- å…¨å±€é…ç½® ---
MSE_THRESHOLD = 0.01
CONTINUE_TRAINING_MODEL = ""
# ã€ä¿®å¤ 1ã€‘ï¼šå‡å°æ‰¹æ¬¡ï¼Œè®©æ¨¡å‹å¤šæ›´æ–°å‡ æ¬¡ï¼Œå¢å¼ºæ³›åŒ–èƒ½åŠ›
BATCH_SIZE = 128  
WINDOW_SIZE = 100

# ==========================================
# 1. è¯»å–æ•°æ® & ç»“æ„åŒ–é‡å¡‘
# ==========================================
print(f"Reading data ({datetime.datetime.now()})...")

try:
    X = np.load("training_data.npy")
    Y = np.load("hr_data.npy")

    # å¯¹ X è¿›è¡Œæ ·æœ¬çº§åˆ«çš„ Z-score æ ‡å‡†åŒ–
    X_mean = np.mean(X, axis=(1, 2), keepdims=True)
    X_std = np.std(X, axis=(1, 2), keepdims=True)
    X = (X - X_mean) / (X_std + 1e-7)

    # å¯¹ Y (å¿ƒç‡æ ‡ç­¾) ä¹Ÿè¿›è¡Œæ ‡å‡†åŒ–
    Y_mean = np.mean(Y)
    Y_std = np.std(Y)
    Y_norm = (Y - Y_mean) / (Y_std + 1e-7)

    # ã€ä¿®å¤ 2ã€‘ï¼šä½¿ç”¨ sklearn å½»åº•æ‰“ä¹±æ•°æ®å¹¶åˆ‡åˆ†ï¼(å…³é”®æ‰€åœ¨)
    print("Splitting data randomly...")
    X_train, X_val, Y_train, Y_val = train_test_split(
        X, Y_norm, test_size=0.2, random_state=42
    )

    print(f"Train samples: {X_train.shape[0]}, Val samples: {X_val.shape[0]}")

except FileNotFoundError:
    print("é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶")
    exit()

# ==========================================
# 2. æ¨¡å‹æ„å»º (Conv1D + LSTM)
# ==========================================
if CONTINUE_TRAINING_MODEL != "":
    model = keras.models.load_model(CONTINUE_TRAINING_MODEL)
else:
    main_input = keras.Input(shape=(WINDOW_SIZE, 192), name='main_input')

    x = keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(main_input)
    x = keras.layers.MaxPooling1D(pool_size=2)(x) 
    # ã€ä¿®å¤ 3ã€‘ï¼šå¢åŠ  Dropoutï¼Œé˜²æ­¢æ­»è®°ç¡¬èƒŒ
    x = keras.layers.Dropout(0.3)(x) 

    x = keras.layers.LSTM(64, return_sequences=True, name='lstm_1')(x)
    x = keras.layers.Dropout(0.3)(x) 

    x = keras.layers.LSTM(32, name='lstm_2')(x)
    x = keras.layers.Dropout(0.3)(x)

    # ã€ä¿®å¤ 4ã€‘ï¼šå¢åŠ  L2 æ­£åˆ™åŒ–æƒ©ç½šï¼Œé™åˆ¶æƒé‡è¿‡å¤§
    x = keras.layers.Dense(16, activation='elu', kernel_regularizer=keras.regularizers.l2(0.01), name='dense_1')(x)
    hr_output = keras.layers.Dense(1, name='hr_output')(x)

    model = keras.Model(inputs=main_input, outputs=hr_output)
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')

# ==========================================
# 3. å¼€å§‹è®­ç»ƒ
# ==========================================
try:
    # ã€ä¿®å¤ 5ã€‘ï¼šä¼ å…¥æˆ‘ä»¬åˆšæ‰å½»åº•æ‰“ä¹±å¥½çš„ X_val å’Œ Y_val
    model.fit(X_train, Y_train,
              epochs=100,
              batch_size=BATCH_SIZE,
              validation_data=(X_val, Y_val), 
              shuffle=True)
except KeyboardInterrupt:
    print("\nğŸ›‘ åœæ­¢è®­ç»ƒ...")

model.save("csi_hr5.keras")

# ==========================================
# 4. é¢„æµ‹æŠ½æŸ¥ (Debug)
# ==========================================
print("\nğŸ” é¢„æµ‹æŠ½æŸ¥ (éªŒè¯é›†éšæœº 10 ä¸ªæ ·æœ¬)")
# ä»éªŒè¯é›†ä¸­æŠ½æŸ¥ï¼Œè¿™æ ·æ›´å®¢è§‚
test_idx = np.random.choice(len(X_val), 10)

preds_norm = model.predict(X_val[test_idx], verbose=0).flatten()

# è¿˜åŸé¢„æµ‹å€¼
preds = preds_norm * Y_std + Y_mean
# è¿˜åŸçœŸå®æ ‡ç­¾
y_true = Y_val[test_idx] * Y_std + Y_mean  

print(f"{'ç´¢å¼•':<5} | {'çœŸå®å¿ƒç‡':<10} | {'é¢„æµ‹å¿ƒç‡':<10} | {'è¯¯å·®':<10}")
for i in range(len(test_idx)):
    print(f"{i:<5} | {y_true[i]:<10.2f} | {preds[i]:<10.2f} | {abs(y_true[i]-preds[i]):<10.2f}")