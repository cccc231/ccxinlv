import tensorflow as tf
from tensorflow import keras
import numpy as np
import os
import datetime

# åªæœ‰åœ¨ Windows ä¸Šæ‰ä¼šæœ‰ dll åŠ è½½é—®é¢˜
if os.name == 'nt':
    try:
        ctypes = __import__('ctypes')
        ctypes.windll.LoadLibrary('cudart64_110.dll')
        print("âœ… æ­å–œï¼šCUDA åŠ¨æ€åº“åŠ è½½æˆåŠŸï¼")
    except OSError:
        print("âŒ å¤±è´¥ï¼šæ‰¾ä¸åˆ° 'cudart64_110.dll'ã€‚")

# --- æ˜¾å¡é…ç½® ---
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)

# --- å…¨å±€é…ç½® ---
MSE_THRESHOLD = 0.01
CONTINUE_TRAINING_MODEL = ""
BATCH_SIZE = 128  
WINDOW_SIZE = 100

# ==========================================
# 1. è¯»å–æ•°æ® & ç»“æ„åŒ–é‡å¡‘
# ==========================================
print(f"Reading data ({datetime.datetime.now()})...")

try:
    X = np.load("training_data.npy")
    Y = np.load("hr_data.npy")

    # å¯¹ X è¿›è¡Œæ ·æœ¬çº§åˆ«çš„ Z-score æ ‡å‡†åŒ–
    X_mean = np.mean(X, axis=(1, 2), keepdims=True)
    X_std = np.std(X, axis=(1, 2), keepdims=True)
    X = (X - X_mean) / (X_std + 1e-7)

    # å¯¹ Y (å¿ƒç‡æ ‡ç­¾) ä¹Ÿè¿›è¡Œæ ‡å‡†åŒ–
    Y_mean = np.mean(Y)
    Y_std = np.std(Y)
    Y_norm = (Y - Y_mean) / (Y_std + 1e-7)

    # ã€ä¿®å¤ã€‘ï¼šé‡‡ç”¨é¡ºåºåˆ‡åˆ†ï¼ˆSequential Splitï¼‰ä»¥é˜²æ­¢ç›¸é‚»æ»‘åŠ¨çª—å£å¯¼è‡´çš„æ•°æ®æ³„éœ²
    print("Splitting data sequentially (Time-series standard)...")
    split_idx = int(len(X) * 0.8)
    X_train, X_val = X[:split_idx], X[split_idx:]
    Y_train, Y_val = Y_norm[:split_idx], Y_norm[split_idx:]

    print(f"Train samples: {X_train.shape[0]}, Val samples: {X_val.shape[0]}")

except FileNotFoundError:
    print("é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶")
    exit()

# ==========================================
# 2. æ¨¡å‹æ„å»º (Conv1D + LSTM)
# ==========================================
if CONTINUE_TRAINING_MODEL != "":
    model = keras.models.load_model(CONTINUE_TRAINING_MODEL)
else:
    main_input = keras.Input(shape=(WINDOW_SIZE, 192), name='main_input')

    x = keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(main_input)
    x = keras.layers.MaxPooling1D(pool_size=2)(x) 
    x = keras.layers.Dropout(0.3)(x) 

    x = keras.layers.LSTM(64, return_sequences=True, name='lstm_1')(x)
    x = keras.layers.Dropout(0.3)(x) 

    x = keras.layers.LSTM(32, name='lstm_2')(x)
    x = keras.layers.Dropout(0.3)(x)

    x = keras.layers.Dense(16, activation='elu', kernel_regularizer=keras.regularizers.l2(0.01), name='dense_1')(x)
    hr_output = keras.layers.Dense(1, name='hr_output')(x)

    model = keras.Model(inputs=main_input, outputs=hr_output)
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')

# ==========================================
# 3. å¼€å§‹è®­ç»ƒ
# ==========================================
try:
    model.fit(X_train, Y_train,
              epochs=100,
              batch_size=BATCH_SIZE,
              validation_data=(X_val, Y_val), 
              shuffle=True)
except KeyboardInterrupt:
    print("
ğŸ›‘ åœæ­¢è®­ç»ƒ...")

model.save("csi_hr_latest.keras")

# ==========================================
# 4. é¢„æµ‹æŠ½æŸ¥ (Debug)
# ==========================================
print("
ğŸ” é¢„æµ‹æŠ½æŸ¥ (éªŒè¯é›†éšæœº 10 ä¸ªæ ·æœ¬)")
test_idx = np.random.choice(len(X_val), 10)
preds_norm = model.predict(X_val[test_idx], verbose=0).flatten()

preds = preds_norm * Y_std + Y_mean
y_true = Y_val[test_idx] * Y_std + Y_mean  

print(f"{'ç´¢å¼•':<5} | {'çœŸå®å¿ƒç‡':<10} | {'é¢„æµ‹å¿ƒç‡':<10} | {'è¯¯å·®':<10}")
for i in range(len(test_idx)):
    print(f"{i:<5} | {y_true[i]:<10.2f} | {preds[i]:<10.2f} | {abs(y_true[i]-preds[i]):<10.2f}")
